{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f8d3a0",
   "metadata": {},
   "source": [
    "# Deep Learning Midterm - Song Release Year Prediction\n",
    "\n",
    "## *Nfal Rifky Atsilah Maulana - 1103223106*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34054b",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Build an end-to-end deep learning regression model to predict song release years from audio features using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fec36d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e4c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83345e6",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df1922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('midterm-regresi-dataset.csv', header=None)\n",
    "\n",
    "# First column is target (release year), rest are features\n",
    "X = df.iloc[:, 1:].values  # Features\n",
    "y = df.iloc[:, 0].values   # Target (release year)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Target range: {y.min()} - {y.max()}\")\n",
    "print(f\"Sample target values: {y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd137535",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA EXPLORATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\n1. Target Statistics:\")\n",
    "print(f\"   Mean: {np.mean(y):.2f}\")\n",
    "print(f\"   Std: {np.std(y):.2f}\")\n",
    "print(f\"   Min: {np.min(y)}\")\n",
    "print(f\"   Max: {np.max(y)}\")\n",
    "print(f\"   Median: {np.median(y)}\")\n",
    "\n",
    "# Distribution of target\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y, bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "plt.title('Distribution of Song Release Years', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=y, color='lightcoral')\n",
    "plt.title('Boxplot of Release Years', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Release Year')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature statistics\n",
    "print(f\"\\n2. Feature Statistics:\")\n",
    "print(f\"   Number of features: {X.shape[1]}\")\n",
    "print(f\"   Feature means (first 5): {np.mean(X, axis=0)[:5]}\")\n",
    "print(f\"   Feature stds (first 5): {np.std(X, axis=0)[:5]}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\n3. Missing Values:\")\n",
    "print(f\"   Features: {np.isnan(X).sum()}\")\n",
    "print(f\"   Target: {np.isnan(y).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f85edf",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08642ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Handle missing values\n",
    "if np.isnan(X).sum() > 0:\n",
    "    print(\"Handling missing values in features...\")\n",
    "    col_means = np.nanmean(X, axis=0)\n",
    "    X = np.where(np.isnan(X), col_means, X)\n",
    "\n",
    "if np.isnan(y).sum() > 0:\n",
    "    print(\"Handling missing values in target...\")\n",
    "    y = np.nan_to_num(y)\n",
    "\n",
    "# Feature scaling\n",
    "print(\"\\nScaling features...\")\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Train-validation split (80-20)\n",
    "print(\"\\nSplitting data into train and validation sets...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"   Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"   Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"   Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c2aa9",
   "metadata": {},
   "source": [
    "## 5. Prepare PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREPARING PYTORCH DATALOADERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val).unsqueeze(1)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"   Batch size: {batch_size}\")\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c33a5",
   "metadata": {},
   "source": [
    "## 6. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BUILDING DEEP LEARNING MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "class DeepRegressionModel(nn.Module):\n",
    "    \"\"\"Deep Neural Network for regression task\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepRegressionModel, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Input layer\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Hidden layer 1\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Hidden layer 2\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Hidden layer 3\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Output layer (single value for regression)\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "model = DeepRegressionModel(input_dim)\n",
    "print(f\"Model Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0cc3a",
   "metadata": {},
   "source": [
    "## 7. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1408d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING SETUP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Loss function (Mean Squared Error for regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "early_stopper = EarlyStopping(patience=10, min_delta=0.001)\n",
    "\n",
    "# Training parameters\n",
    "n_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d801c",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baed1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_X)\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            predictions = model(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            val_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping check\n",
    "    early_stopper(val_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}/{n_epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.6f} | \"\n",
    "              f\"Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7754a8f9",
   "metadata": {},
   "source": [
    "## 9. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING VISUALIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_losses, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Loss (MSE)', fontsize=12, fontweight='bold')\n",
    "plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Plot final predictions vs actual\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_predictions_scaled = model(X_val_tensor.to(device)).cpu().numpy()\n",
    "    \n",
    "# Convert back to original scale\n",
    "val_predictions = scaler_y.inverse_transform(val_predictions_scaled)\n",
    "val_actual = scaler_y.inverse_transform(y_val_tensor.numpy())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(val_actual, val_predictions, alpha=0.6, color='steelblue')\n",
    "plt.plot([val_actual.min(), val_actual.max()], \n",
    "         [val_actual.min(), val_actual.max()], \n",
    "         'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Release Year', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Predicted Release Year', fontsize=12, fontweight='bold')\n",
    "plt.title('Predictions vs Actual', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922f590",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Validation set predictions\n",
    "    val_predictions_scaled = model(X_val_tensor.to(device)).cpu().numpy()\n",
    "    val_predictions = scaler_y.inverse_transform(val_predictions_scaled)\n",
    "    val_actual = scaler_y.inverse_transform(y_val_tensor.numpy())\n",
    "    \n",
    "    # Training set predictions\n",
    "    train_predictions_scaled = model(X_train_tensor.to(device)).cpu().numpy()\n",
    "    train_predictions = scaler_y.inverse_transform(train_predictions_scaled)\n",
    "    train_actual = scaler_y.inverse_transform(y_train_tensor.numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "def calculate_metrics(actual, predicted):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    return mse, rmse, mae, r2\n",
    "\n",
    "train_mse, train_rmse, train_mae, train_r2 = calculate_metrics(train_actual, train_predictions)\n",
    "val_mse, val_rmse, val_mae, val_r2 = calculate_metrics(val_actual, val_predictions)\n",
    "\n",
    "print(\"\\n1. Performance Metrics:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Metric':<10} {'Training':>12} {'Validation':>12}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'MSE':<10} {train_mse:>12.4f} {val_mse:>12.4f}\")\n",
    "print(f\"{'RMSE':<10} {train_rmse:>12.4f} {val_rmse:>12.4f}\")\n",
    "print(f\"{'MAE':<10} {train_mae:>12.4f} {val_mae:>12.4f}\")\n",
    "print(f\"{'R²':<10} {train_r2:>12.4f} {val_r2:>12.4f}\")\n",
    "\n",
    "# Interpretation of results\n",
    "print(\"\\n2. Interpretation of Results:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"• Mean Absolute Error (MAE): {val_mae:.2f} years\")\n",
    "print(f\"  → On average, predictions are off by {val_mae:.2f} years\")\n",
    "print(f\"• Root Mean Squared Error (RMSE): {val_rmse:.2f} years\")\n",
    "print(f\"• R² Score: {val_r2:.4f}\")\n",
    "if val_r2 > 0.7:\n",
    "    print(f\"  → Good fit (explains {val_r2*100:.1f}% of variance)\")\n",
    "elif val_r2 > 0.5:\n",
    "    print(f\"  → Moderate fit (explains {val_r2*100:.1f}% of variance)\")\n",
    "else:\n",
    "    print(f\"  → Poor fit (explains only {val_r2*100:.1f}% of variance)\")\n",
    "\n",
    "# Error distribution\n",
    "errors = val_actual - val_predictions\n",
    "print(f\"• Error Statistics:\")\n",
    "print(f\"  Mean error: {np.mean(errors):.2f} years\")\n",
    "print(f\"  Std of errors: {np.std(errors):.2f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d99a1",
   "metadata": {},
   "source": [
    "## 11. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Error distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(errors, bins=30, edgecolor='black', alpha=0.7, color='lightcoral')\n",
    "plt.xlabel('Prediction Error (Years)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "plt.title('Distribution of Prediction Errors', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Errors vs actual values\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(val_actual, errors, alpha=0.6, color='steelblue')\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Actual Release Year', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Prediction Error', fontsize=12, fontweight='bold')\n",
    "plt.title('Errors vs Actual Values', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Prediction vs actual with errors\n",
    "plt.subplot(2, 2, 3)\n",
    "for i in range(min(100, len(val_actual))):\n",
    "    plt.plot([val_actual[i], val_actual[i]], \n",
    "             [val_actual[i], val_predictions[i]], \n",
    "             'gray', alpha=0.5)\n",
    "plt.scatter(val_actual[:100], val_predictions[:100], alpha=0.7, color='green')\n",
    "plt.plot([val_actual.min(), val_actual.max()], \n",
    "         [val_actual.min(), val_actual.max()], \n",
    "         'r--', linewidth=2)\n",
    "plt.xlabel('Actual Release Year', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Predicted Release Year', fontsize=12, fontweight='bold')\n",
    "plt.title('Predictions with Error Bars (First 100 samples)', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(val_predictions, errors, alpha=0.6, color='purple')\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Release Year', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Residuals', fontsize=12, fontweight='bold')\n",
    "plt.title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea0eab",
   "metadata": {},
   "source": [
    "## 12. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbab8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAVING MODEL AND RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'input_dim': input_dim,\n",
    "    'scaler_X': scaler_X,\n",
    "    'scaler_y': scaler_y\n",
    "}, 'deep_regression_model.pth')\n",
    "\n",
    "print(\"✓ Model saved as 'deep_regression_model.pth'\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual_Year': val_actual.flatten(),\n",
    "    'Predicted_Year': val_predictions.flatten(),\n",
    "    'Absolute_Error': np.abs(errors).flatten()\n",
    "})\n",
    "predictions_df.to_csv('predictions_results.csv', index=False)\n",
    "print(\"✓ Predictions saved as 'predictions_results.csv'\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Dataset': ['Training', 'Validation'],\n",
    "    'MSE': [train_mse, val_mse],\n",
    "    'RMSE': [train_rmse, val_rmse],\n",
    "    'MAE': [train_mae, val_mae],\n",
    "    'R2': [train_r2, val_r2]\n",
    "})\n",
    "metrics_df.to_csv('model_metrics.csv', index=False)\n",
    "print(\"✓ Metrics saved as 'model_metrics.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"END OF DEEP LEARNING MIDTERM PROJECT\")\n",
    "print(\"=\"*50)\n",
    "print(\"Student: Nfal Rifky Atsilah Maulana\")\n",
    "print(\"NIM: 1103223106\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
